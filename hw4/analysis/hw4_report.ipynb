{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Sampling for HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "\\begin{align}\n",
    "P(Y_t = y | Y_{-t} = y_{-t}, X = x) & = \\frac{P(Y_t = y, Y_{-t} = y_{-t}, X = x)}{P(Y_{-t} = y_{-t}, X = x)}\\\\\n",
    "& = \\frac{P(Y_1 = y_1) \\Pi_{i = 2}^T P(Y_i = y_i | Y_{i-1} = y_{i-1}) \\Pi_{i = 1}^T P(X_i = x_i | Y_i = y_i)}\n",
    "{\\int P(Y_{-t} = y_{-t}, X = x, Y_t = y) dy}\\\\\n",
    "& = \\frac{const \\times P(Y_t = y | Y_{t-1} = y_{t-1}) P(Y_{t+1} = y_{t+1} | Y_{t} = y) P(X_t = x_t | Y_t = y)}{const}\\\\\n",
    "& \\propto P(Y_t = y | Y_{t-1} = y_{t-1}) P(Y_{t+1} = y_{t+1} | Y_{t} = y) P(X_t = x_t | Y_t = y)\n",
    "\\end{align}\n",
    "\n",
    "Note I just leave out terms not relevant to $y$ as constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "For $t = 1$, from the same formula above, we get \n",
    "$$P(Y_1 = y | Y_{-1} = y_{-1}, X = x) \\propto P(Y_{2} = y_{2} | Y_{1} = y) P(Y_{1} = y | Y_{0} = <s>) P(X_1 = x_1 | Y_1 = y)$$\n",
    "\n",
    "For $t = T$, from the same formula above, we get \n",
    "$$P(Y_T = y | Y_{-T} = y_{-T}, X = x) \\propto P(</s> | Y_{T} = y) P(Y_{T} = y | Y_{T-1} = y_{T-1}) P(X_T = x_T | Y_T = y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) \n",
    "code is implemented in `../code/gibbs.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../code\")\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "from gibbs import gibbs, gibbs_predictor\n",
    "from data_pre import data_preprocessing\n",
    "from misc import compute_prob_log,compute_tag_acc\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train,data_dev,word2ix, ix2word, tag2ix, ix2tag, em_prob, trans_prob) = data_preprocessing()\n",
    "em_prob[em_prob == 0] = sys.float_info.min\n",
    "trans_prob[trans_prob == 0] = sys.float_info.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using gibbs sampling is 0.8617097415506958\n",
      "log prob of gibbs prediction is -166849.2765407818\n",
      "runtime for gibbs sampling with K = 5 is 4.791851043701172\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(corpus, tags) = data_dev\n",
    "K = 5\n",
    "start = time.time()\n",
    "(tags_pred, n_changes) = gibbs_predictor(corpus, em_prob, trans_prob, tag2ix, word2ix,ix2tag, K=K)   \n",
    "runtime = time.time() - start\n",
    "print(\"accuracy using gibbs sampling is {}\".format(compute_tag_acc(tags_pred, tags)))\n",
    "print(\"log prob of gibbs prediction is {}\".format(compute_prob_log(corpus, tags_pred, trans_prob, em_prob, word2ix, tag2ix)))\n",
    "print(\"runtime for gibbs sampling with K = {} is {}\".format(K, runtime))\n",
    "n_changes = np.array(n_changes)\n",
    "plt.plot(n_changes.mean(axis = 0))\n",
    "plt.title(\"N_iter vs average changes \")\n",
    "plt.xlabel(\"N_iter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "With number of iterations growing, the number of changes decrease (but not to zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "beta    K       accuracy                log_prob                runtime\n",
    "1       2       0.77769                 -182094.522             1.66\n",
    "1       5       0.86306                 -166691.174             6.20\n",
    "1       10      0.86306                 -166567.8591            13.63\n",
    "1       50      0.86739                 -166290.0117            73.42\n",
    "1       100     0.86600                 -166424.6044            148.67\n",
    "1       500     0.86620                 -166448.0571            751.69\n",
    "1       1000    0.86656                 -166428.1011            1456.29\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "beta    K       accuracy                log_prob                runtime\n",
    "0.5     2       0.63391                 -224944.2369            1.482\n",
    "0.5     5       0.75964                 -190808.6695            5.585\n",
    "0.5     10      0.76131                 -189674.8019            12.375\n",
    "0.5     50      0.76222                 -189671.6142            67.006\n",
    "0.5     100     0.76465                 -189178.4236            134.737\n",
    "0.5     500     0.76290                 -189445.7034            680.403\n",
    "0.5     1000    0.76314                 -189630.1784            1363.908\n",
    "\n",
    "\n",
    "beta    K       accuracy                log_prob                runtime\n",
    "2       2       0.79908                 -180006.4834            1.515\n",
    "2       5       0.87514                 -164752.6507            5.502\n",
    "2       10      0.87980                 -164395.3786            12.224\n",
    "2       50      0.88163                 -164146.4202            66.037\n",
    "2       100     0.88294                 -164019.4404            133.281\n",
    "2       500     0.88369                 -163981.8099            673.306\n",
    "2       1000    0.88504                 -163908.7458            1355.406\n",
    "\n",
    "\n",
    "beta    K       accuracy                log_prob                runtime\n",
    "5       2       0.80278                 -179218.0286            1.4738\n",
    "5       5       0.87964                 -164219.2186            5.5659\n",
    "5       10      0.88159                 -164029.0525            12.2327\n",
    "5       50      0.88214                 -163926.8255            66.0533\n",
    "5       100     0.88457                 -163783.9662            133.5858\n",
    "5       500     0.88473                 -163752.7453            675.1857\n",
    "5       1000    0.88687                 -163625.3498            1353.0155\n",
    "```\n",
    "\n",
    "### Comment:\n",
    "With bigger $\\beta$, we get better accuacry and log_prob for almost all $K$s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start from $\\beta = 0.1$, then increase it by $0.1$  in each iteration\n",
    "```\n",
    "K       accuracy        log_prob        runtime\n",
    "2       0.01964         -1968835.9106   1.43\n",
    "5       0.39328         -311310.4384    5.50\n",
    "10      0.84608         -169426.5513    12.34\n",
    "50      0.88819         -163498.2672    67.07\n",
    "100     0.89001         -163392.3143    135.69\n",
    "500     0.87153         -169634.7072    686.12\n",
    "1000    0.17518         -434717.2169    1418.21\n",
    "```\n",
    "\n",
    "### adjust scheduling by setting a cap for $\\beta$\n",
    "From the experiments above, we can see when $\\beta$ gets too large interations, the log-probability becomes very bad, probably because huge $\\beta$ makes a very wrong model. In order to remedy it, I decide to add a cap to the value of $\\beta$. That is, when $\\beta$ hits a certain value (called \"cap\" below), it ceases to increase. \n",
    "\n",
    "Below are the results. The running time are almost the same, so I don't show them below. \n",
    "\n",
    "#### cap = 5\n",
    "```\n",
    "cap     K       accuracy        log_prob\n",
    "5       2       0.0191          -1853046.976\n",
    "5       10      0.3889          -169562.0827\n",
    "5       50      0.8483          -163439.8790\n",
    "5       100     0.8886          -163460.3735\n",
    "5       500     0.8898          -163454.1597\n",
    "5       1000    0.8906          -163411.5830\n",
    "```\n",
    "#### cap = 10\n",
    "```\n",
    "cap     K       accuracy        log_prob\n",
    "10      2       0.0191          -1939250.1183\n",
    "10      5       0.3951          -311397.0808\n",
    "10      10      0.8468          -169616.2551\n",
    "10      50      0.8879          -163487.1764\n",
    "10      100     0.8908          -163358.5868\n",
    "10      500     0.8899          -163387.2232\n",
    "10      1000    0.8905          -163371.0516\n",
    "```\n",
    "\n",
    "### Comment:\n",
    "By setting a cap on $\\beta$, we can see both accuracy and log_prob has small increase compared to the one without capping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Sampling for Minimum Bayes Risk Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "Let $$L(y) = \\sum_{y'} P(Y = y' | X = x) $$ where cost is 1-0 cost.\n",
    "Then we know $$L(y) = \\sum_{y' \\neq y} P(Y = y' | X = x) = 1 - P(Y = y | X = x)$$\n",
    "Therefore $$ \\hat{y} = \\text{argmin}_{y} L(y) = \\text{argmax}_{y} P(Y = y | X = x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "Easy to see that we can approximate with \n",
    "\n",
    "$$ P(Y_t | X = x) \\approx \\frac{1}{K} \\sum_{i = 1}^K 1_{[\\tilde{y}_t^{(i)} = y]} $$\n",
    "\n",
    "So bascially, for a location $t$, we only need to see which tags appear most often among all samples. \n",
    "\n",
    "Below I give a more detailed proof:\n",
    "\n",
    "From equation (5), we have:\n",
    "\\begin{align}\n",
    "P(Y_t = y | X = x) & = \\sum_{y_{-t}} P(Y_t = y, Y_{-t} = y_{-t} | X = x) \\\\\n",
    "& \\approx \\sum_{y_{-t}} \\frac{1}{K} \\sum_{i = 1}^K 1_{\\tilde{y}^{(i)} = y_t}\\\\\n",
    "& = \\frac{1}{K} \\sum_{i = 1}^K \\sum_{y_{-t}} 1_{(\\tilde{y_t}^{(i)} = y,\\tilde{y_{-t}}^{(i)} = y_{-t} )}\\\\\n",
    "& = \\frac{1}{K} \\sum_{i = 1}^K 1_{[\\tilde{y}_t^{(i)} = y]}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "\n",
    "It is implemented in `code/gibbs.py`\n",
    "\n",
    "### $\\beta = 1$\n",
    "```\n",
    "beta    K       accuracy          runtime\n",
    "1       2       0.3967              2\n",
    "1       5       0.8607              6\n",
    "1       10      0.8780              13\n",
    "1       50      0.8893              70\n",
    "1       100     0.8906              142\n",
    "1       500     0.8930              717\n",
    "1       1000    0.8939              1439\n",
    "\n",
    "```\n",
    "\n",
    "### Other values of $\\beta$\n",
    "For different $\\beta$, the runtime are similar, so I do not show them below. \n",
    "\n",
    "### $\\beta = 0.5$\n",
    "```\n",
    "beta    K       accuracy        \n",
    "0.5     2       0.3163          \n",
    "0.5     5       0.8078          \n",
    "0.5     10      0.8570          \n",
    "0.5     50      0.8823          \n",
    "0.5     100     0.8875          \n",
    "0.5     500     0.8910          \n",
    "0.5     1000    0.8915          \n",
    "```\n",
    "\n",
    "\n",
    "### $\\beta = 2$\n",
    "```\n",
    "beta    K       accuracy        \n",
    "2       2       0.40429        \n",
    "2       5       0.87176         \n",
    "2       10      0.88159         \n",
    "2       50      0.88715         \n",
    "2       100     0.88886         \n",
    "2       500     0.89109        \n",
    "2       1000    0.89204         \n",
    "```\n",
    "\n",
    "### $\\beta = 5$\n",
    "```\n",
    "beta    K       accuracy\n",
    "5       2       0.4079\n",
    "5       5       0.8750\n",
    "5       10      0.8815\n",
    "5       50      0.8843\n",
    "5       100     0.8858\n",
    "5       500     0.8880\n",
    "5       1000    0.8873\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### $\\beta = 10$\n",
    "```\n",
    "beta    K       accuracy       \n",
    "10      2       0.41025         \n",
    "10      5       0.87296         \n",
    "10      10      0.88206         \n",
    "10      50      0.88083         \n",
    "10      100     0.88377         \n",
    "10      500     0.88433         \n",
    "10      1000    0.88628         \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "* MBR with $\\beta = 1, K = 1000$ gets the best result I have seen so far. \n",
    "\n",
    "* Accuracy increases with $K$.\n",
    "\n",
    "* $\\beta = 1$ gets the best result for large $K$. Increasing $\\beta$ beyond 1 decreases the accuracy. \n",
    "\n",
    "* This is different from what I observed from using the final sample, which shows the trend that increasing $\\beta$ increases accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
