{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So far:\n",
    "pad sentence and record ending index\n",
    "\n",
    "But cannot index properly...\n",
    "\n",
    "So how can I do batching??? Well, pad it with . zero. Just let it learn? How the effect of 0 will not be too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WAC import WAC\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "def getdata(name, data_dir=\"../data/\"):\n",
    "    with open(data_dir + name) as f:\n",
    "        outX = []\n",
    "        outy = []\n",
    "        for sent in f.readlines():\n",
    "            Xy = sent.split()\n",
    "            outX.append(Xy[:-1])\n",
    "            outy.append(int(Xy[-1]))\n",
    "        #outy = torch.Tensor(outy)\n",
    "    return  outX, np.array(outy)\n",
    "\n",
    "def build_dict(trainX, testX, devX):\n",
    "    import numpy as np\n",
    "    train_flat = [x for item in trainX  for x in item]\n",
    "    test_flat = [x for item in testX  for x in item]\n",
    "    dev_flat = [x for item in devX  for x in item]\n",
    "\n",
    "    total_unique = np.unique(train_flat + test_flat + dev_flat)\n",
    "    voc_ix = {}\n",
    "    for ix, word in enumerate(total_unique):\n",
    "        voc_ix[word] = ix + 1\n",
    "\n",
    "    return voc_ix\n",
    "\n",
    "def corpus2ix(corpus, voc_ix):\n",
    "    out = []\n",
    "    for sent in corpus:\n",
    "        out.append([voc_ix[w] for w in sent])\n",
    "    return out\n",
    "\n",
    "def pad_features(reviews_int, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "    '''\n",
    "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
    "    end_ix = np.zeros(len(reviews_int), dtype = int)\n",
    "    \n",
    "    for i, review in enumerate(reviews_int):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= seq_length:\n",
    "            zeroes = list(np.zeros(seq_length-review_len))\n",
    "            new = review + zeroes\n",
    "        elif review_len > seq_length:\n",
    "            new = review[0:seq_length]\n",
    "        \n",
    "        features[i,:] = np.array(new)\n",
    "        end_ix[i] = review_len\n",
    "    \n",
    "    return features, end_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 1.4221277236938477\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "(trainX, trainy) = getdata('senti.train.tsv')\n",
    "(testX, testy) = getdata('senti.test.tsv')\n",
    "(devX, devy) = getdata('senti.dev.tsv')\n",
    "\n",
    "## build dictionary\n",
    "voc_ix = build_dict(trainX, testX, devX)\n",
    "\n",
    "## word2ix\n",
    "trainX = corpus2ix(trainX, voc_ix)\n",
    "testX = corpus2ix(testX, voc_ix)\n",
    "devX = corpus2ix(devX, voc_ix)\n",
    "\n",
    "## padding\n",
    "Seq_length = max([len(x) for x in trainX] + \\\n",
    "                 [len(x) for x in testX]+[len(x) for x in devX])\n",
    "trainX,  train_endi = pad_features(trainX, Seq_length)\n",
    "testX,  test_endi = pad_features(testX, Seq_length)\n",
    "devX,  dev_endi = pad_features(devX, Seq_length)\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(trainX),\\\n",
    "                           torch.from_numpy(trainy),torch.from_numpy(train_endi))\n",
    "test_data = TensorDataset(torch.from_numpy(testX),\\\n",
    "                           torch.from_numpy(testy),torch.from_numpy(test_endi))\n",
    "dev_data = TensorDataset(torch.from_numpy(devX),\\\n",
    "                           torch.from_numpy(devy),torch.from_numpy(dev_endi))\n",
    "\n",
    "print(\"runtime: {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import log\n",
    "import torch.optim as optim\n",
    "from WAC import WAC\n",
    "\n",
    "\n",
    "'''\n",
    "load and prepare data\n",
    "'''\n",
    "#(voc_ix, trainX, trainy, testX, testy, devX, devy) = data_preprocessing()\n",
    "#print(\"finish preparing data\\n\")\n",
    "\n",
    "'''\n",
    "set parameters\n",
    "'''\n",
    "## set hyperparameters\n",
    "VOCAB_SIZE = len(voc_ix) + 1\n",
    "EMBEDDING_DIM = 100\n",
    "n_epoch = 10\n",
    "batch_size = 500\n",
    "eval_per = 5000/batch_size\n",
    "PATH = \"../model/wac_batch.pt\"\n",
    "\n",
    "## define model\n",
    "model = WAC(EMBEDDING_DIM, VOCAB_SIZE)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr = 1e-2, lr_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "time: 0.013703107833862305\n",
      "accuracy on dev: 0.4908256880733945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([500])) that is different to the input size (torch.Size([500, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.43471217155456543\n",
      "accuracy on dev: 0.5091743119266054\n",
      "time: 0.7742490768432617\n",
      "accuracy on dev: 0.5091743119266054\n",
      "time: 1.0980091094970703\n",
      "accuracy on dev: 0.5114678899082569\n",
      "time: 1.449465036392212\n",
      "accuracy on dev: 0.5114678899082569\n",
      "time: 1.8102221488952637\n",
      "accuracy on dev: 0.5240825688073395\n",
      "time: 2.167250156402588\n",
      "accuracy on dev: 0.536697247706422\n",
      "time: 2.501955032348633\n",
      "accuracy on dev: 0.5412844036697247\n",
      "time: 2.8400492668151855\n",
      "accuracy on dev: 0.5424311926605505\n",
      "time: 3.1480650901794434\n",
      "accuracy on dev: 0.5607798165137615\n",
      "time: 3.4833991527557373\n",
      "accuracy on dev: 0.6009174311926605\n",
      "time: 3.8150510787963867\n",
      "accuracy on dev: 0.5848623853211009\n",
      "time: 4.121809244155884\n",
      "accuracy on dev: 0.6456422018348624\n",
      "time: 4.525230169296265\n",
      "accuracy on dev: 0.6811926605504587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([349])) that is different to the input size (torch.Size([349, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "time: 4.8874900341033936\n",
      "accuracy on dev: 0.676605504587156\n",
      "time: 5.269345998764038\n",
      "accuracy on dev: 0.6823394495412844\n",
      "time: 5.60003924369812\n",
      "accuracy on dev: 0.680045871559633\n",
      "time: 5.925462007522583\n",
      "accuracy on dev: 0.6708715596330275\n",
      "time: 6.254996061325073\n",
      "accuracy on dev: 0.7075688073394495\n",
      "time: 6.6338889598846436\n",
      "accuracy on dev: 0.7018348623853211\n",
      "time: 7.044145107269287\n",
      "accuracy on dev: 0.694954128440367\n",
      "time: 7.417456150054932\n",
      "accuracy on dev: 0.7213302752293578\n",
      "time: 7.757629871368408\n",
      "accuracy on dev: 0.7006880733944955\n",
      "time: 8.083674192428589\n",
      "accuracy on dev: 0.7064220183486238\n",
      "time: 8.418361186981201\n",
      "accuracy on dev: 0.7018348623853211\n",
      "time: 8.726108074188232\n",
      "accuracy on dev: 0.7064220183486238\n",
      "time: 9.05339002609253\n",
      "accuracy on dev: 0.7144495412844036\n",
      "epoch 2\n",
      "time: 9.360318899154663\n",
      "accuracy on dev: 0.7305045871559633\n",
      "time: 9.690591096878052\n",
      "accuracy on dev: 0.7373853211009175\n",
      "time: 10.026754140853882\n",
      "accuracy on dev: 0.7350917431192661\n",
      "time: 10.385966062545776\n",
      "accuracy on dev: 0.7236238532110092\n",
      "time: 10.756904125213623\n",
      "accuracy on dev: 0.7477064220183486\n",
      "time: 11.09605598449707\n",
      "accuracy on dev: 0.7305045871559633\n",
      "time: 11.42749810218811\n",
      "accuracy on dev: 0.7396788990825688\n",
      "time: 11.75761103630066\n",
      "accuracy on dev: 0.7431192660550459\n",
      "time: 12.08302116394043\n",
      "accuracy on dev: 0.7339449541284404\n",
      "time: 12.45517110824585\n",
      "accuracy on dev: 0.7522935779816514\n",
      "time: 12.795667886734009\n",
      "accuracy on dev: 0.7477064220183486\n",
      "time: 13.119322061538696\n",
      "accuracy on dev: 0.7545871559633027\n",
      "time: 13.461839199066162\n",
      "accuracy on dev: 0.7385321100917431\n",
      "time: 13.819441080093384\n",
      "accuracy on dev: 0.75\n",
      "epoch 3\n",
      "time: 14.191318035125732\n",
      "accuracy on dev: 0.7534403669724771\n",
      "time: 14.524057149887085\n",
      "accuracy on dev: 0.7614678899082569\n",
      "time: 14.885395288467407\n",
      "accuracy on dev: 0.7545871559633027\n",
      "time: 15.207129001617432\n",
      "accuracy on dev: 0.7522935779816514\n",
      "time: 15.542447090148926\n",
      "accuracy on dev: 0.7557339449541285\n",
      "time: 15.93638801574707\n",
      "accuracy on dev: 0.7545871559633027\n",
      "time: 16.26251792907715\n",
      "accuracy on dev: 0.7580275229357798\n",
      "time: 16.6109881401062\n",
      "accuracy on dev: 0.7614678899082569\n",
      "time: 16.94732117652893\n",
      "accuracy on dev: 0.7614678899082569\n",
      "time: 17.272417068481445\n",
      "accuracy on dev: 0.7649082568807339\n",
      "time: 17.65053415298462\n",
      "accuracy on dev: 0.7637614678899083\n",
      "time: 17.997514009475708\n",
      "accuracy on dev: 0.7614678899082569\n",
      "time: 18.33340811729431\n",
      "accuracy on dev: 0.7637614678899083\n",
      "epoch 4\n",
      "time: 18.674331188201904\n",
      "accuracy on dev: 0.7603211009174312\n",
      "time: 19.001397132873535\n",
      "accuracy on dev: 0.7637614678899083\n",
      "time: 19.349000930786133\n",
      "accuracy on dev: 0.7626146788990825\n",
      "time: 19.69219207763672\n",
      "accuracy on dev: 0.7660550458715596\n",
      "time: 20.044816255569458\n",
      "accuracy on dev: 0.7614678899082569\n",
      "time: 20.394376277923584\n",
      "accuracy on dev: 0.7649082568807339\n",
      "time: 20.753823041915894\n",
      "accuracy on dev: 0.7694954128440367\n",
      "time: 21.101473093032837\n",
      "accuracy on dev: 0.768348623853211\n",
      "time: 21.406928062438965\n",
      "accuracy on dev: 0.7717889908256881\n",
      "time: 21.732755184173584\n",
      "accuracy on dev: 0.7717889908256881\n",
      "time: 22.040596961975098\n",
      "accuracy on dev: 0.7717889908256881\n",
      "time: 22.404335021972656\n",
      "accuracy on dev: 0.768348623853211\n",
      "time: 22.73966097831726\n",
      "accuracy on dev: 0.7672018348623854\n",
      "time: 23.06441020965576\n",
      "accuracy on dev: 0.7672018348623854\n",
      "epoch 5\n",
      "time: 23.40110421180725\n",
      "accuracy on dev: 0.7717889908256881\n",
      "time: 23.73969316482544\n",
      "accuracy on dev: 0.7706422018348624\n",
      "time: 24.04804301261902\n",
      "accuracy on dev: 0.7694954128440367\n",
      "time: 24.40172529220581\n",
      "accuracy on dev: 0.7672018348623854\n",
      "time: 24.728644132614136\n",
      "accuracy on dev: 0.7660550458715596\n",
      "time: 25.072493076324463\n",
      "accuracy on dev: 0.7672018348623854\n",
      "time: 25.44229817390442\n",
      "accuracy on dev: 0.768348623853211\n",
      "time: 25.76981019973755\n",
      "accuracy on dev: 0.7706422018348624\n",
      "time: 26.094683170318604\n",
      "accuracy on dev: 0.7786697247706422\n",
      "time: 26.442291975021362\n",
      "accuracy on dev: 0.7798165137614679\n",
      "time: 26.766354084014893\n",
      "accuracy on dev: 0.7717889908256881\n",
      "time: 27.111513137817383\n",
      "accuracy on dev: 0.7706422018348624\n",
      "time: 27.431769132614136\n",
      "accuracy on dev: 0.7740825688073395\n",
      "epoch 6\n",
      "time: 27.746458053588867\n",
      "accuracy on dev: 0.7821100917431193\n",
      "time: 28.081688165664673\n",
      "accuracy on dev: 0.7821100917431193\n",
      "time: 28.410154104232788\n",
      "accuracy on dev: 0.7775229357798165\n",
      "time: 28.72251605987549\n",
      "accuracy on dev: 0.7740825688073395\n",
      "time: 29.038896083831787\n",
      "accuracy on dev: 0.7729357798165137\n",
      "time: 29.36043691635132\n",
      "accuracy on dev: 0.7752293577981652\n",
      "time: 29.671916007995605\n",
      "accuracy on dev: 0.7729357798165137\n",
      "time: 30.01949119567871\n",
      "accuracy on dev: 0.7752293577981652\n",
      "time: 30.343179941177368\n",
      "accuracy on dev: 0.7786697247706422\n",
      "time: 30.662931203842163\n",
      "accuracy on dev: 0.7786697247706422\n",
      "time: 30.9795560836792\n",
      "accuracy on dev: 0.7786697247706422\n",
      "time: 31.30448889732361\n",
      "accuracy on dev: 0.7798165137614679\n",
      "time: 31.661237001419067\n",
      "accuracy on dev: 0.7798165137614679\n",
      "time: 31.966533184051514\n",
      "accuracy on dev: 0.786697247706422\n",
      "epoch 7\n",
      "time: 32.29096007347107\n",
      "accuracy on dev: 0.7809633027522935\n",
      "time: 32.610350131988525\n",
      "accuracy on dev: 0.7809633027522935\n",
      "time: 32.93974804878235\n",
      "accuracy on dev: 0.7821100917431193\n",
      "time: 33.25978493690491\n",
      "accuracy on dev: 0.7821100917431193\n",
      "time: 33.57957410812378\n",
      "accuracy on dev: 0.7809633027522935\n",
      "time: 33.90384817123413\n",
      "accuracy on dev: 0.7821100917431193\n",
      "time: 34.22696805000305\n",
      "accuracy on dev: 0.7821100917431193\n",
      "time: 34.58339190483093\n",
      "accuracy on dev: 0.786697247706422\n",
      "time: 34.895015239715576\n",
      "accuracy on dev: 0.7889908256880734\n",
      "time: 35.23248100280762\n",
      "accuracy on dev: 0.7821100917431193\n",
      "time: 35.566035985946655\n",
      "accuracy on dev: 0.783256880733945\n",
      "time: 35.86913514137268\n",
      "accuracy on dev: 0.7889908256880734\n",
      "time: 36.21134114265442\n",
      "accuracy on dev: 0.783256880733945\n",
      "epoch 8\n",
      "time: 36.53933620452881\n",
      "accuracy on dev: 0.7844036697247706\n",
      "time: 36.84182810783386\n",
      "accuracy on dev: 0.783256880733945\n",
      "time: 37.162148237228394\n",
      "accuracy on dev: 0.786697247706422\n",
      "time: 37.48445200920105\n",
      "accuracy on dev: 0.7901376146788991\n",
      "time: 37.817694902420044\n",
      "accuracy on dev: 0.7901376146788991\n",
      "time: 38.118513107299805\n",
      "accuracy on dev: 0.7912844036697247\n",
      "time: 38.44671893119812\n",
      "accuracy on dev: 0.7901376146788991\n",
      "time: 38.78302526473999\n",
      "accuracy on dev: 0.7855504587155964\n",
      "time: 39.10473918914795\n",
      "accuracy on dev: 0.7924311926605505\n",
      "time: 39.43442988395691\n",
      "accuracy on dev: 0.7889908256880734\n",
      "time: 39.76956796646118\n",
      "accuracy on dev: 0.7935779816513762\n",
      "time: 40.11500597000122\n",
      "accuracy on dev: 0.7912844036697247\n",
      "time: 40.462056159973145\n",
      "accuracy on dev: 0.7889908256880734\n",
      "time: 40.78279495239258\n",
      "accuracy on dev: 0.7935779816513762\n",
      "epoch 9\n",
      "time: 41.087133169174194\n",
      "accuracy on dev: 0.7924311926605505\n",
      "time: 41.40834712982178\n",
      "accuracy on dev: 0.7924311926605505\n",
      "time: 41.725971937179565\n",
      "accuracy on dev: 0.7924311926605505\n",
      "time: 42.05418109893799\n",
      "accuracy on dev: 0.7901376146788991\n",
      "time: 42.37643003463745\n",
      "accuracy on dev: 0.7912844036697247\n",
      "time: 42.69282507896423\n",
      "accuracy on dev: 0.7935779816513762\n",
      "time: 43.05468416213989\n",
      "accuracy on dev: 0.7958715596330275\n",
      "time: 43.43501114845276\n",
      "accuracy on dev: 0.7947247706422018\n",
      "time: 43.751986265182495\n",
      "accuracy on dev: 0.7912844036697247\n",
      "time: 44.060774087905884\n",
      "accuracy on dev: 0.7844036697247706\n",
      "time: 44.375824213027954\n",
      "accuracy on dev: 0.7912844036697247\n",
      "time: 44.69768214225769\n",
      "accuracy on dev: 0.7912844036697247\n",
      "time: 45.0682110786438\n",
      "accuracy on dev: 0.7912844036697247\n",
      "runtime: 45.38208818435669s\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "losses = []\n",
    "accs = []\n",
    "i = 0\n",
    "best_dev_acc = 0\n",
    "\n",
    "myloss = torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "start = time.time()\n",
    "for epoch in range(n_epoch):\n",
    "    print(\"epoch \" + str(epoch))\n",
    "    \n",
    "    #dataloaders\n",
    "    # make sure to SHUFFLE your data\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "    for X,y,ix in train_loader:\n",
    "\n",
    "        if i % eval_per == 0:\n",
    "            print(\"time: {}\".format(time.time() - start))\n",
    "            acc = model.evaluate(dev_data.tensors)\n",
    "            if acc > best_dev_acc:\n",
    "                best_dev_acc = acc\n",
    "                torch.save(model, PATH)\n",
    "            print(\"accuracy on dev: \" + str(acc))\n",
    "            accs.append(acc)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        prob = model.forward(torch.t(X))\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        #loss_sent = - y*log(prob) - (1-y)*log(1-prob)\n",
    "        loss = myloss(prob, y.float())\n",
    "        #loss += loss_sent\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        i +=1\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime) + \"s\")\n",
    "\n",
    "# model_best = torch.load(PATH)\n",
    "# model_best.eval()\n",
    "# acc_dev = model_best.evaluate(devX, devy)\n",
    "# print(\"best model acc on dev: \" + str(acc_dev))\n",
    "# acc_test = model_best.evaluate(testX, testy)\n",
    "# print(\"best model acc on test: \" + str(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8050521691378364"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
