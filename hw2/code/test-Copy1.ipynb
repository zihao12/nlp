{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So far:\n",
    "pad sentence and record ending index\n",
    "\n",
    "But cannot index properly...\n",
    "\n",
    "So how can I do batching??? Well, pad it with . zero. Just let it learn? How the effect of 0 will not be too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 1.5681426525115967\n"
     ]
    }
   ],
   "source": [
    "from data_pre import data_preprocessing\n",
    "from data_pre import data_preprocessing\n",
    "from WAC import WAC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import log\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "(voc_ix, train_data,test_data, dev_data) = data_preprocessing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import log\n",
    "import torch.optim as optim\n",
    "from WAC_ATT import WAC_ATT\n",
    "\n",
    "\n",
    "'''\n",
    "load and prepare data\n",
    "'''\n",
    "#(voc_ix, trainX, trainy, testX, testy, devX, devy) = data_preprocessing()\n",
    "#print(\"finish preparing data\\n\")\n",
    "\n",
    "'''\n",
    "set parameters\n",
    "'''\n",
    "## set hyperparameters\n",
    "VOCAB_SIZE = len(voc_ix) + 1\n",
    "EMBEDDING_DIM = 100\n",
    "n_epoch = 20\n",
    "batch_size = 500\n",
    "eval_per = 20000/batch_size\n",
    "PATH = \"../model/wac_batch.pt\"\n",
    "\n",
    "## define model\n",
    "model = WAC_ATT(EMBEDDING_DIM, VOCAB_SIZE)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr = 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "dataiter = iter(train_loader)\n",
    "X,y,lens = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(voc_ix) + 1\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = nn.Embedding(VOCAB_SIZE, embedding_dim, sparse = True)\n",
    "u = nn.Embedding(1,embedding_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = word_embeddings(X)\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = nn.CosineSimilarity(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = X.size(1)\n",
    "mask = torch.arange(maxlen)[None,:] < lens[:,None]\n",
    "\n",
    "## compute attention\n",
    "att = torch.exp(cosine(u.weight.data.view(1,1,-1), embeds))\n",
    "\n",
    "att[~mask] = float(0) \n",
    "att = att/att.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, maxlen = X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0002, 0.0002, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0002, 0.0002, 0.0002,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0002, 0.0002, 0.0002,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0002, 0.0002, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0002, 0.0002, 0.0002,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0002, 0.0002, 0.0002,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(mask.float(), att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.sum(dim = 1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "att /= att.sum(dim = 1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0739, 0.0818, 0.0718,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.1399, 0.1494, 0.1275,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0874, 0.0821, 0.0744,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.3660, 0.3153, 0.3187,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0283, 0.0260, 0.0356,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.1749, 0.1519, 0.1619,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(att.t()/att.sum(dim = 1)).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(att.view(att.size()[0],att.size()[1],1), embeds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "view(): argument 'size' must be tuple of ints, but found element of type torch.Size at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-6a5707b392fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: view(): argument 'size' must be tuple of ints, but found element of type torch.Size at pos 2"
     ]
    }
   ],
   "source": [
    "att.view(1,att.size()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "time: 0.010152816772460938\n",
      "accuracy on dev: 0.5091743119266054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([500])) that is different to the input size (torch.Size([500, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.1987669467926025\n",
      "accuracy on dev: 0.6754587155963303\n",
      "time: 6.3477160930633545\n",
      "accuracy on dev: 0.7213302752293578\n",
      "time: 9.533467769622803\n",
      "accuracy on dev: 0.7649082568807339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([349])) that is different to the input size (torch.Size([349, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "time: 12.702982902526855\n",
      "accuracy on dev: 0.7786697247706422\n",
      "time: 15.80125904083252\n",
      "accuracy on dev: 0.783256880733945\n",
      "time: 19.02666687965393\n",
      "accuracy on dev: 0.7935779816513762\n",
      "epoch 2\n",
      "time: 22.10341191291809\n",
      "accuracy on dev: 0.7947247706422018\n",
      "time: 25.053172826766968\n",
      "accuracy on dev: 0.8004587155963303\n",
      "time: 28.016375064849854\n",
      "accuracy on dev: 0.801605504587156\n",
      "time: 30.925309896469116\n",
      "accuracy on dev: 0.8084862385321101\n",
      "epoch 3\n",
      "time: 33.86204385757446\n",
      "accuracy on dev: 0.8027522935779816\n",
      "time: 36.84261202812195\n",
      "accuracy on dev: 0.805045871559633\n",
      "time: 39.788776874542236\n",
      "accuracy on dev: 0.8073394495412844\n",
      "epoch 4\n",
      "time: 42.9779748916626\n",
      "accuracy on dev: 0.8073394495412844\n",
      "time: 46.166455030441284\n",
      "accuracy on dev: 0.8142201834862385\n",
      "time: 49.41793894767761\n",
      "accuracy on dev: 0.8119266055045872\n",
      "epoch 5\n",
      "time: 52.51468896865845\n",
      "accuracy on dev: 0.8073394495412844\n",
      "time: 55.61316990852356\n",
      "accuracy on dev: 0.8084862385321101\n",
      "time: 58.71389889717102\n",
      "accuracy on dev: 0.8096330275229358\n",
      "time: 62.20643091201782\n",
      "accuracy on dev: 0.8084862385321101\n",
      "epoch 6\n",
      "time: 66.03278684616089\n",
      "accuracy on dev: 0.8119266055045872\n",
      "time: 70.06116604804993\n",
      "accuracy on dev: 0.8176605504587156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-175cecd5e226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Step 3. Run our forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Step 4. Compute the loss, gradients, and update the parameters by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/nlp/hw2/code/WAC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, lens)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;31m## set padding to be 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0membeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0;31m## average for non-padding embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0membeds_ave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "## training\n",
    "losses = []\n",
    "accs = []\n",
    "i = 0\n",
    "best_dev_acc = 0\n",
    "\n",
    "myloss = torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "start = time.time()\n",
    "for epoch in range(n_epoch):\n",
    "    print(\"epoch \" + str(epoch))\n",
    "    \n",
    "    #dataloaders\n",
    "    # make sure to SHUFFLE your data\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "    for X,y,lens in train_loader:\n",
    "\n",
    "        if i % eval_per == 0:\n",
    "            print(\"time: {}\".format(time.time() - start))\n",
    "            acc = model.evaluate(dev_data.tensors)\n",
    "            if acc > best_dev_acc:\n",
    "                best_dev_acc = acc\n",
    "                torch.save(model, PATH)\n",
    "            print(\"accuracy on dev: \" + str(acc))\n",
    "            accs.append(acc)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        prob = model.forward(X, lens)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        #loss_sent = - y*log(prob) - (1-y)*log(1-prob)\n",
    "        loss = myloss(prob, y.float())\n",
    "        #loss += loss_sent\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        i +=1\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime) + \"s\")\n",
    "\n",
    "model_best = torch.load(PATH)\n",
    "model_best.eval()\n",
    "acc_dev = model_best.evaluate(dev_data.tensors)\n",
    "print(\"best model acc on dev: \" + str(acc_dev))\n",
    "acc_test = model_best.evaluate(test_data.tensors)\n",
    "print(\"best model acc on test: \" + str(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "batch_size = 500\n",
    "train_loader = DataLoader(train_data, shuffle=F, batch_size=batch_size)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "X, y,lens = dataiter.next()\n",
    "\n",
    "embeds = model.word_embeddings(X)\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = X.size(1)\n",
    "mask = torch.arange(maxlen)[None,:] < lens[:,None]\n",
    "embeds[~mask] = float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12407, 18639,  9777, 19227, 11647, 10646,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeds.sum(dim = 1).t()/lens.float()).t()[0,:]/model.word_embeddings(X[0,:6]).mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 100])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_embeddings(X[0,:9]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  1,  4,  3, 10,  9,  3, 20,  8, 21, 10, 12,  7, 13,  6, 13,  9, 12,\n",
       "         6, 13,  5,  2,  6,  3,  2, 11, 20, 15, 25,  3, 13,  4,  6, 10,  2,  3,\n",
       "         3, 27,  5, 19,  9, 18,  3,  5,  1,  9, 19, 15,  6, 14,  4,  6, 11, 18,\n",
       "         9,  6, 14,  8,  5, 22, 10, 15, 10,  4,  8, 13,  4, 17,  7,  6,  1, 23,\n",
       "         9, 27,  2,  7,  5,  1,  5,  4, 12,  2, 27, 23, 31,  3, 25,  8,  7,  4,\n",
       "         6,  5, 19,  8,  4,  1,  6, 14,  5,  2,  3, 15,  4,  9, 11,  1,  2,  9,\n",
       "         1,  8, 30, 14,  3, 15, 15,  2,  4, 16, 11,  4,  4,  2, 13, 14, 12,  8,\n",
       "        12,  2,  2, 19, 12,  6, 10, 19,  6, 16,  7,  3,  7, 34, 10,  6,  8,  2,\n",
       "         4,  5,  1, 18, 16,  5, 18, 10,  8,  6, 22,  1,  7,  2,  2,  8,  2,  2,\n",
       "         7,  1,  6,  6,  4, 12, 33, 17,  7,  2,  1, 20,  8,  5,  1,  8,  2,  5,\n",
       "         5,  1, 34,  3, 11,  1,  7,  3, 10,  2,  5, 30,  8,  9,  2, 25, 11, 18,\n",
       "         4, 11,  4,  3,  3,  9,  8, 10,  6,  3,  3,  2,  4,  8,  3, 33, 15,  3,\n",
       "         3,  7, 13, 10,  9,  3, 28,  3,  1, 32,  5,  7,  5,  1,  1, 10,  3,  4,\n",
       "        15, 22,  3, 31, 10,  8,  9,  7,  3,  8,  8, 19,  4,  5,  4, 11, 15,  7,\n",
       "        11, 15,  4,  5,  3, 28, 34, 24,  5,  2,  2,  5,  5,  3, 10, 11,  3,  2,\n",
       "        10,  2, 12,  3,  4, 16,  4,  6,  5, 24,  7,  1,  8, 10,  9, 17, 10,  9,\n",
       "         2,  4, 27,  4, 13, 16,  2, 30,  5,  2,  1,  2, 10,  2,  5, 22,  6,  3,\n",
       "         2,  8,  6,  3, 17, 23,  2,  3, 13, 25,  3,  3, 16, 24,  5,  1,  2,  3,\n",
       "        30, 17,  3, 15,  3, 11,  1,  3, 23, 13, 16,  9,  5, 15,  8,  1, 14,  4,\n",
       "         2, 12,  9, 10,  3,  2, 10,  1,  3,  7,  3,  4,  1,  5,  2, 14,  3,  3,\n",
       "         8, 24,  6, 25,  2,  3,  2,  3,  2,  2, 22,  2,  2,  1, 22, 11,  7, 22,\n",
       "        12,  2,  7, 19, 20, 10, 30,  1,  4, 16,  1, 24, 10,  3,  4,  2, 24, 12,\n",
       "         2,  7,  6, 10,  4,  3,  3, 25,  2, 21, 23,  8,  8,  6,  8,  2,  3,  4,\n",
       "         2, 12,  3,  2,  3, 28,  3,  9,  6, 11, 10,  2,  3,  2,  8,  8, 18,  5,\n",
       "        22,  5, 18,  8,  6, 18, 10,  5,  3, 21,  2,  3,  4, 42, 15,  4, 14, 24,\n",
       "         4, 11,  4,  3,  4,  8,  4,  2, 23,  5,  3, 20,  2, 32,  3,  7, 14,  4,\n",
       "        13,  9, 13, 21, 28, 17, 25, 11,  7,  2,  4,  2,  6,  3,  2,  7, 10,  2,\n",
       "         6,  1,  4,  2,  2,  9,  9,  6, 19,  5, 33, 13,  4,  9])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  8, 14,  9, 28,  9,  2,  9,  5, 18, 28,  2, 56, 14,  6, 56,  9,  3,\n",
       "         4, 56,  4,  2, 56, 11, 56,  2,  3,  8,  5,  7, 11,  4,  4,  4,  8,  5,\n",
       "         8,  8, 18,  8,  8,  5, 28,  3, 11,  4,  4,  4, 28, 14,  4, 18, 14, 28,\n",
       "         9, 18,  2,  2,  1,  9,  3, 28, 18, 56, 11,  5, 56,  7, 14,  8,  6, 56,\n",
       "        56, 28,  4,  7,  2, 14, 14, 28,  4,  4, 18,  2, 56,  5, 28,  3,  2,  9,\n",
       "         4, 28,  2,  3,  3,  3,  2,  2,  9, 11,  4, 14, 18, 11, 28, 14,  4, 18,\n",
       "         2, 14,  3, 18, 18, 28, 11, 56,  5,  4,  5,  4,  2, 14,  9, 28, 56,  2,\n",
       "        14,  8,  7,  7, 14, 28,  4,  9,  2, 14, 56,  5,  7,  9, 14,  2, 18,  4,\n",
       "        56,  2,  5, 11, 18,  4, 11,  4,  5,  3,  9, 11,  9,  7,  3,  5, 28,  2,\n",
       "        56, 56,  5, 28,  8,  5, 56,  1, 56, 56, 18, 18,  3,  4, 28,  4,  7,  3,\n",
       "         8,  9,  4, 28,  6,  8,  4,  6,  2, 28, 56, 18,  1,  7,  8, 56,  3,  2,\n",
       "         6,  6,  6, 56, 18, 56, 28,  2,  7,  6, 11,  7, 28, 14,  7,  6, 56, 14,\n",
       "         2, 28,  6,  4,  3,  2,  9,  1, 56,  8,  3,  5,  6, 18, 18,  8,  3,  5,\n",
       "         6,  5, 18, 11,  4,  5,  5,  2, 18, 28, 18,  6,  4,  4, 11,  4,  2,  7,\n",
       "        14,  3,  4, 11, 28, 18,  3,  5,  2,  7, 14, 11,  7,  9,  2, 56, 14,  2,\n",
       "         4, 56,  4, 11,  2,  1, 56, 18,  5,  4, 18, 18,  7, 28,  9, 56,  3,  6,\n",
       "         1,  9, 56,  6, 11,  8,  6, 11, 14, 28, 18,  5,  8, 28, 28,  9, 11,  5,\n",
       "         3, 18, 28,  9, 28,  9, 28,  4, 18,  2,  3,  2,  2,  3,  7,  9, 28, 18,\n",
       "         3,  5,  5,  5, 18,  8,  7,  9, 18, 14, 11, 14, 18,  2, 11,  8,  2,  6,\n",
       "        18, 14, 11,  6,  4, 56,  5,  7, 11,  4,  2,  8,  2,  3, 14,  9,  8,  2,\n",
       "         2,  2,  9,  1, 28, 28, 14,  6,  2,  6,  2,  7, 18,  2,  6,  3, 56, 11,\n",
       "         3,  2,  8,  5,  7,  4,  6, 11, 28, 18,  4, 56, 28, 14,  2, 11,  3, 14,\n",
       "        14,  3,  3, 14, 11,  4, 18,  3, 11, 28, 11,  2, 28,  4,  7,  8, 56, 28,\n",
       "        56, 18,  1,  9,  4, 56, 14,  4, 56,  2,  6,  2,  3,  4,  7,  2,  5,  5,\n",
       "        14,  2,  6,  5, 18,  2, 14, 11, 11, 14, 28,  8, 28, 28, 11,  9,  3,  4,\n",
       "         2,  3, 14,  8,  3,  3,  7,  5, 28,  4, 18, 11, 14, 28,  5,  8, 14,  1,\n",
       "         5,  8, 56,  9,  6,  9,  3, 18, 28,  2,  5, 18, 14,  9,  5,  9,  3, 11,\n",
       "         2,  5, 14,  4, 28, 28, 28,  2,  5, 56, 14,  2,  2, 28])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen/lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds[2,6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeds.mean(dim = 1).t()*(maxlen/lens.float())).t()[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(maxlen/lens.float(),embeds.mean(dim = 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a 2D tensor, but self is 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-43a58eb494e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/nlp/hw2/code/WAC.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/nlp/hw2/code/WAC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, lens)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0membeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;31m## average for non-padding embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0membeds_ave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds_ave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore2prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a 2D tensor, but self is 3D"
     ]
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5355504587155964"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dev_data.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([872])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.tensors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c88b29576794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/nlp/hw2/code/WAC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, lens)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m## build a mask for paddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0;31m## set padding to be 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0membeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "x = dev_data.tensors[0][0,:]\n",
    "y = dev_data.tensors[1][0]\n",
    "\n",
    "model.forward(x.unsqueeze(0),lens = torch.Tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4732]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(x.unsqueeze(0),lens = torch.tensor([1], dtype = torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.long, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
