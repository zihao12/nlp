{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So far:\n",
    "pad sentence and record ending index\n",
    "\n",
    "But cannot index properly...\n",
    "\n",
    "So how can I do batching??? Well, pad it with . zero. Just let it learn? How the effect of 0 will not be too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 1.5681426525115967\n"
     ]
    }
   ],
   "source": [
    "from data_pre import data_preprocessing\n",
    "from data_pre import data_preprocessing\n",
    "from WAC import WAC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import log\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "(voc_ix, train_data,test_data, dev_data) = data_preprocessing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import log\n",
    "import torch.optim as optim\n",
    "from WAC_ATT import WAC_ATT\n",
    "\n",
    "\n",
    "'''\n",
    "load and prepare data\n",
    "'''\n",
    "#(voc_ix, trainX, trainy, testX, testy, devX, devy) = data_preprocessing()\n",
    "#print(\"finish preparing data\\n\")\n",
    "\n",
    "'''\n",
    "set parameters\n",
    "'''\n",
    "## set hyperparameters\n",
    "VOCAB_SIZE = len(voc_ix) + 1\n",
    "EMBEDDING_DIM = 100\n",
    "n_epoch = 20\n",
    "batch_size = 500\n",
    "eval_per = 20000/batch_size\n",
    "PATH = \"../model/wac_batch.pt\"\n",
    "\n",
    "## define model\n",
    "model = WAC_ATT(EMBEDDING_DIM, VOCAB_SIZE)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr = 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "dataiter = iter(train_loader)\n",
    "X,y,lens = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(voc_ix) + 1\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = nn.Embedding(VOCAB_SIZE, embedding_dim, sparse = True)\n",
    "u = nn.Embedding(1,embedding_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = word_embeddings(X)\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = nn.CosineSimilarity(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = X.size(1)\n",
    "mask = torch.arange(maxlen)[None,:] < lens[:,None]\n",
    "\n",
    "## compute attention\n",
    "att = torch.exp(cosine(u.weight.data.view(1,1,-1), embeds))\n",
    "\n",
    "att[~mask] = float(0) \n",
    "att = att/att.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, maxlen = X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0002, 0.0002, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0002, 0.0002, 0.0002,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0002, 0.0002, 0.0002,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0002, 0.0002, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0002, 0.0002, 0.0002,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0002, 0.0002, 0.0002,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(mask.float(), att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.sum(dim = 1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "att /= att.sum(dim = 1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0739, 0.0818, 0.0718,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.1399, 0.1494, 0.1275,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0874, 0.0821, 0.0744,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.3660, 0.3153, 0.3187,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0283, 0.0260, 0.0356,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.1749, 0.1519, 0.1619,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(att.t()/att.sum(dim = 1)).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(att.view(att.size()[0],att.size()[1],1), embeds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "view(): argument 'size' must be tuple of ints, but found element of type torch.Size at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-6a5707b392fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: view(): argument 'size' must be tuple of ints, but found element of type torch.Size at pos 2"
     ]
    }
   ],
   "source": [
    "att.view(1,att.size()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(embeds, embeds).sum(dim = 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 15, 27,  3,  6,  1,  2, 33, 15, 10,  3,  3, 10, 25, 12,  1, 10,  1,\n",
       "         3,  6,  7, 13,  3, 11,  2,  2,  3, 25, 18,  7,  6,  2, 18, 12, 16, 10,\n",
       "         5,  2,  4, 17,  4, 25,  5, 19,  8,  1, 13,  4, 14,  1, 34, 17, 13,  8,\n",
       "        11, 10,  7, 11,  4, 17,  4,  2, 27, 25,  1, 20,  2, 12,  2, 19, 28, 24,\n",
       "         1, 16,  3,  1, 12, 12, 10,  5, 31,  8,  8,  6, 22,  7,  3, 21,  3,  5,\n",
       "         1,  8,  3,  9,  5,  5, 12,  6,  3,  8,  2,  2,  3, 17,  1,  8,  2,  3,\n",
       "        16, 28,  6,  5,  2, 23,  2,  1,  4,  8, 23,  9,  4, 24,  4,  1,  2, 16,\n",
       "         9, 16, 31,  2,  1,  5, 24,  2,  7, 10, 12,  2,  2,  3, 11,  3,  9,  5,\n",
       "         5, 32, 30, 11, 20,  3, 23, 20,  4,  9, 16, 17,  4,  1,  3,  2,  7,  2,\n",
       "         2, 39,  2, 11, 15, 14,  4, 25, 21, 15, 14,  9,  6,  2,  6, 20,  3, 12,\n",
       "        17,  2, 12,  1, 36,  8, 15,  1, 15, 12,  9,  4,  2,  4, 10,  4,  2,  7,\n",
       "         8,  9,  6,  2, 25, 12,  2,  2, 27, 23, 22,  7,  5,  7,  8,  8,  2,  5,\n",
       "         4, 15, 15, 12,  7,  5,  1,  4, 16,  4,  7,  3,  5,  3, 11, 16,  1,  3,\n",
       "        25, 30, 19,  2,  3, 22,  5,  2, 17,  4,  1, 17,  4,  5, 31,  5,  6, 26,\n",
       "        15, 11, 16, 12,  4, 22,  7,  2,  3,  6, 15,  3,  1,  3, 19, 12, 10,  8,\n",
       "         7,  3,  6, 11,  4, 10, 27,  2, 13, 26, 17,  4,  3,  9,  6,  6,  7,  7,\n",
       "         1,  9, 35,  1,  2,  3,  7,  2, 19, 13, 18,  8, 16, 25,  2, 28,  5, 12,\n",
       "         1,  6, 11,  3,  2,  9,  2, 10,  4, 28,  7, 17,  1,  6, 18, 14,  1,  5,\n",
       "         3, 27,  4, 19, 21,  3, 25,  1, 18,  4,  2,  6,  2, 30,  5,  2,  2,  2,\n",
       "         1, 19, 14,  3,  8,  2,  9,  4, 10, 18,  1,  6, 15, 19,  4, 22,  2,  3,\n",
       "         9,  6,  4,  3, 21, 23,  3, 25,  4,  2,  4,  8, 20, 16, 22, 15,  3, 26,\n",
       "         4, 12, 16, 14,  7,  9,  6, 12,  3,  5,  6, 13,  7, 12,  8,  7,  1, 12,\n",
       "        34,  2, 36, 10,  5,  7,  2, 15, 10,  5,  6, 16,  7,  3,  1, 42,  3, 11,\n",
       "        11,  8,  3,  2,  5, 26,  2, 19,  9,  4,  2, 21, 13,  5, 17,  2,  6,  2,\n",
       "         2,  4,  8,  9,  4, 26,  1,  2, 36, 13,  3,  2,  1,  3,  3, 31,  3, 19,\n",
       "        22, 18,  4,  4,  2, 29, 10,  2, 20,  9,  8,  6,  4,  3,  2, 14, 16, 10,\n",
       "         4, 13,  4,  3, 14,  4,  3,  3,  8,  9,  3, 23, 13,  2, 17,  7, 28, 22,\n",
       "         6,  4, 15, 12,  4,  8,  3,  3,  7, 16, 17,  2, 22,  4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds_mean = torch.mul(mask.unsqueeze(2).float(), embeds).mean(dim = 1)\n",
    "embeds_mean = embeds_mean.mul((maxlen/lens).unsqueeze(1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2545e-02, -9.0677e-03, -3.6350e-02,  1.9701e-02,  3.3840e-02,\n",
       "         4.4991e-02, -2.3492e-03,  3.3255e-02,  2.9349e-02, -1.3542e-02,\n",
       "        -2.9385e-02,  2.1722e-02,  5.1253e-03, -8.0544e-03, -1.4661e-02,\n",
       "         2.0961e-03,  3.4882e-02,  4.9197e-02, -1.5508e-02, -3.2877e-02,\n",
       "         1.4496e-02, -3.3729e-03,  5.5681e-02,  2.1760e-02,  2.9044e-02,\n",
       "        -3.2889e-02,  1.4972e-03,  1.8613e-02,  4.5386e-02,  2.1909e-02,\n",
       "        -1.1360e-02, -2.3841e-02, -9.9702e-03, -1.2315e-02,  1.7632e-03,\n",
       "         2.7768e-02,  6.8033e-03, -4.7548e-03,  1.7184e-02,  1.1790e-03,\n",
       "         1.3299e-02, -4.1601e-03, -1.4265e-02, -7.1131e-03, -3.5834e-02,\n",
       "        -4.2925e-02,  3.7214e-02,  5.4426e-03,  3.5782e-02, -3.3906e-03,\n",
       "         2.8505e-02,  1.5165e-02, -1.3841e-02, -2.0364e-02,  2.6180e-02,\n",
       "        -2.7734e-02,  7.9024e-03,  3.9405e-02,  4.1891e-02, -4.0047e-02,\n",
       "        -1.2652e-02,  2.7053e-02, -3.0833e-02,  1.3080e-02, -2.0985e-02,\n",
       "         1.2611e-02,  4.4108e-02,  7.1553e-03,  9.1806e-03,  1.0531e-02,\n",
       "        -8.1314e-02, -5.5654e-03, -1.0485e-02,  3.2529e-02,  8.3079e-03,\n",
       "        -2.0127e-02, -6.5600e-04, -2.8856e-02, -5.4501e-04,  2.9345e-02,\n",
       "         6.3159e-03, -3.6714e-02,  1.0271e-02, -3.2909e-02, -2.4717e-02,\n",
       "         2.7421e-02, -2.0472e-05,  5.8630e-03, -1.7995e-02, -4.8793e-02,\n",
       "         6.7866e-03, -1.4192e-02, -1.9891e-03,  5.1135e-02, -4.8630e-03,\n",
       "        -1.6267e-02, -2.3713e-03,  1.4846e-02,  2.2877e-02, -1.9153e-02],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds_mean[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds_mean2 = embeds_mean.mul((maxlen/lens).unsqueeze(1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 100])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeds_mean2/embeds_mean).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
       "        3.0000], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeds_mean2/embeds_mean)[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28,  3,  2, 18,  9, 56, 28,  1,  3,  5, 18, 18,  5,  2,  4, 56,  5, 56,\n",
       "        18,  9,  8,  4, 18,  5, 28, 28, 18,  2,  3,  8,  9, 28,  3,  4,  3,  5,\n",
       "        11, 28, 14,  3, 14,  2, 11,  2,  7, 56,  4, 14,  4, 56,  1,  3,  4,  7,\n",
       "         5,  5,  8,  5, 14,  3, 14, 28,  2,  2, 56,  2, 28,  4, 28,  2,  2,  2,\n",
       "        56,  3, 18, 56,  4,  4,  5, 11,  1,  7,  7,  9,  2,  8, 18,  2, 18, 11,\n",
       "        56,  7, 18,  6, 11, 11,  4,  9, 18,  7, 28, 28, 18,  3, 56,  7, 28, 18,\n",
       "         3,  2,  9, 11, 28,  2, 28, 56, 14,  7,  2,  6, 14,  2, 14, 56, 28,  3,\n",
       "         6,  3,  1, 28, 56, 11,  2, 28,  8,  5,  4, 28, 28, 18,  5, 18,  6, 11,\n",
       "        11,  1,  1,  5,  2, 18,  2,  2, 14,  6,  3,  3, 14, 56, 18, 28,  8, 28,\n",
       "        28,  1, 28,  5,  3,  4, 14,  2,  2,  3,  4,  6,  9, 28,  9,  2, 18,  4,\n",
       "         3, 28,  4, 56,  1,  7,  3, 56,  3,  4,  6, 14, 28, 14,  5, 14, 28,  8,\n",
       "         7,  6,  9, 28,  2,  4, 28, 28,  2,  2,  2,  8, 11,  8,  7,  7, 28, 11,\n",
       "        14,  3,  3,  4,  8, 11, 56, 14,  3, 14,  8, 18, 11, 18,  5,  3, 56, 18,\n",
       "         2,  1,  2, 28, 18,  2, 11, 28,  3, 14, 56,  3, 14, 11,  1, 11,  9,  2,\n",
       "         3,  5,  3,  4, 14,  2,  8, 28, 18,  9,  3, 18, 56, 18,  2,  4,  5,  7,\n",
       "         8, 18,  9,  5, 14,  5,  2, 28,  4,  2,  3, 14, 18,  6,  9,  9,  8,  8,\n",
       "        56,  6,  1, 56, 28, 18,  8, 28,  2,  4,  3,  7,  3,  2, 28,  2, 11,  4,\n",
       "        56,  9,  5, 18, 28,  6, 28,  5, 14,  2,  8,  3, 56,  9,  3,  4, 56, 11,\n",
       "        18,  2, 14,  2,  2, 18,  2, 56,  3, 14, 28,  9, 28,  1, 11, 28, 28, 28,\n",
       "        56,  2,  4, 18,  7, 28,  6, 14,  5,  3, 56,  9,  3,  2, 14,  2, 28, 18,\n",
       "         6,  9, 14, 18,  2,  2, 18,  2, 14, 28, 14,  7,  2,  3,  2,  3, 18,  2,\n",
       "        14,  4,  3,  4,  8,  6,  9,  4, 18, 11,  9,  4,  8,  4,  7,  8, 56,  4,\n",
       "         1, 28,  1,  5, 11,  8, 28,  3,  5, 11,  9,  3,  8, 18, 56,  1, 18,  5,\n",
       "         5,  7, 18, 28, 11,  2, 28,  2,  6, 14, 28,  2,  4, 11,  3, 28,  9, 28,\n",
       "        28, 14,  7,  6, 14,  2, 56, 28,  1,  4, 18, 28, 56, 18, 18,  1, 18,  2,\n",
       "         2,  3, 14, 14, 28,  1,  5, 28,  2,  6,  7,  9, 14, 18, 28,  4,  3,  5,\n",
       "        14,  4, 14, 18,  4, 14, 18, 18,  7,  6, 18,  2,  4, 28,  3,  8,  2,  2,\n",
       "         9, 14,  3,  4, 14,  7, 18, 18,  8,  3,  3, 28,  2, 14])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen/lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "batch_size = 500\n",
    "train_loader = DataLoader(train_data, shuffle=F, batch_size=batch_size)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "X, y,lens = dataiter.next()\n",
    "\n",
    "embeds = model.word_embeddings(X)\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = X.size(1)\n",
    "mask = torch.arange(maxlen)[None,:] < lens[:,None]\n",
    "embeds[~mask] = float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12407, 18639,  9777, 19227, 11647, 10646,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeds.sum(dim = 1).t()/lens.float()).t()[0,:]/model.word_embeddings(X[0,:6]).mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 100])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_embeddings(X[0,:9]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  1,  4,  3, 10,  9,  3, 20,  8, 21, 10, 12,  7, 13,  6, 13,  9, 12,\n",
       "         6, 13,  5,  2,  6,  3,  2, 11, 20, 15, 25,  3, 13,  4,  6, 10,  2,  3,\n",
       "         3, 27,  5, 19,  9, 18,  3,  5,  1,  9, 19, 15,  6, 14,  4,  6, 11, 18,\n",
       "         9,  6, 14,  8,  5, 22, 10, 15, 10,  4,  8, 13,  4, 17,  7,  6,  1, 23,\n",
       "         9, 27,  2,  7,  5,  1,  5,  4, 12,  2, 27, 23, 31,  3, 25,  8,  7,  4,\n",
       "         6,  5, 19,  8,  4,  1,  6, 14,  5,  2,  3, 15,  4,  9, 11,  1,  2,  9,\n",
       "         1,  8, 30, 14,  3, 15, 15,  2,  4, 16, 11,  4,  4,  2, 13, 14, 12,  8,\n",
       "        12,  2,  2, 19, 12,  6, 10, 19,  6, 16,  7,  3,  7, 34, 10,  6,  8,  2,\n",
       "         4,  5,  1, 18, 16,  5, 18, 10,  8,  6, 22,  1,  7,  2,  2,  8,  2,  2,\n",
       "         7,  1,  6,  6,  4, 12, 33, 17,  7,  2,  1, 20,  8,  5,  1,  8,  2,  5,\n",
       "         5,  1, 34,  3, 11,  1,  7,  3, 10,  2,  5, 30,  8,  9,  2, 25, 11, 18,\n",
       "         4, 11,  4,  3,  3,  9,  8, 10,  6,  3,  3,  2,  4,  8,  3, 33, 15,  3,\n",
       "         3,  7, 13, 10,  9,  3, 28,  3,  1, 32,  5,  7,  5,  1,  1, 10,  3,  4,\n",
       "        15, 22,  3, 31, 10,  8,  9,  7,  3,  8,  8, 19,  4,  5,  4, 11, 15,  7,\n",
       "        11, 15,  4,  5,  3, 28, 34, 24,  5,  2,  2,  5,  5,  3, 10, 11,  3,  2,\n",
       "        10,  2, 12,  3,  4, 16,  4,  6,  5, 24,  7,  1,  8, 10,  9, 17, 10,  9,\n",
       "         2,  4, 27,  4, 13, 16,  2, 30,  5,  2,  1,  2, 10,  2,  5, 22,  6,  3,\n",
       "         2,  8,  6,  3, 17, 23,  2,  3, 13, 25,  3,  3, 16, 24,  5,  1,  2,  3,\n",
       "        30, 17,  3, 15,  3, 11,  1,  3, 23, 13, 16,  9,  5, 15,  8,  1, 14,  4,\n",
       "         2, 12,  9, 10,  3,  2, 10,  1,  3,  7,  3,  4,  1,  5,  2, 14,  3,  3,\n",
       "         8, 24,  6, 25,  2,  3,  2,  3,  2,  2, 22,  2,  2,  1, 22, 11,  7, 22,\n",
       "        12,  2,  7, 19, 20, 10, 30,  1,  4, 16,  1, 24, 10,  3,  4,  2, 24, 12,\n",
       "         2,  7,  6, 10,  4,  3,  3, 25,  2, 21, 23,  8,  8,  6,  8,  2,  3,  4,\n",
       "         2, 12,  3,  2,  3, 28,  3,  9,  6, 11, 10,  2,  3,  2,  8,  8, 18,  5,\n",
       "        22,  5, 18,  8,  6, 18, 10,  5,  3, 21,  2,  3,  4, 42, 15,  4, 14, 24,\n",
       "         4, 11,  4,  3,  4,  8,  4,  2, 23,  5,  3, 20,  2, 32,  3,  7, 14,  4,\n",
       "        13,  9, 13, 21, 28, 17, 25, 11,  7,  2,  4,  2,  6,  3,  2,  7, 10,  2,\n",
       "         6,  1,  4,  2,  2,  9,  9,  6, 19,  5, 33, 13,  4,  9])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  8, 14,  9, 28,  9,  2,  9,  5, 18, 28,  2, 56, 14,  6, 56,  9,  3,\n",
       "         4, 56,  4,  2, 56, 11, 56,  2,  3,  8,  5,  7, 11,  4,  4,  4,  8,  5,\n",
       "         8,  8, 18,  8,  8,  5, 28,  3, 11,  4,  4,  4, 28, 14,  4, 18, 14, 28,\n",
       "         9, 18,  2,  2,  1,  9,  3, 28, 18, 56, 11,  5, 56,  7, 14,  8,  6, 56,\n",
       "        56, 28,  4,  7,  2, 14, 14, 28,  4,  4, 18,  2, 56,  5, 28,  3,  2,  9,\n",
       "         4, 28,  2,  3,  3,  3,  2,  2,  9, 11,  4, 14, 18, 11, 28, 14,  4, 18,\n",
       "         2, 14,  3, 18, 18, 28, 11, 56,  5,  4,  5,  4,  2, 14,  9, 28, 56,  2,\n",
       "        14,  8,  7,  7, 14, 28,  4,  9,  2, 14, 56,  5,  7,  9, 14,  2, 18,  4,\n",
       "        56,  2,  5, 11, 18,  4, 11,  4,  5,  3,  9, 11,  9,  7,  3,  5, 28,  2,\n",
       "        56, 56,  5, 28,  8,  5, 56,  1, 56, 56, 18, 18,  3,  4, 28,  4,  7,  3,\n",
       "         8,  9,  4, 28,  6,  8,  4,  6,  2, 28, 56, 18,  1,  7,  8, 56,  3,  2,\n",
       "         6,  6,  6, 56, 18, 56, 28,  2,  7,  6, 11,  7, 28, 14,  7,  6, 56, 14,\n",
       "         2, 28,  6,  4,  3,  2,  9,  1, 56,  8,  3,  5,  6, 18, 18,  8,  3,  5,\n",
       "         6,  5, 18, 11,  4,  5,  5,  2, 18, 28, 18,  6,  4,  4, 11,  4,  2,  7,\n",
       "        14,  3,  4, 11, 28, 18,  3,  5,  2,  7, 14, 11,  7,  9,  2, 56, 14,  2,\n",
       "         4, 56,  4, 11,  2,  1, 56, 18,  5,  4, 18, 18,  7, 28,  9, 56,  3,  6,\n",
       "         1,  9, 56,  6, 11,  8,  6, 11, 14, 28, 18,  5,  8, 28, 28,  9, 11,  5,\n",
       "         3, 18, 28,  9, 28,  9, 28,  4, 18,  2,  3,  2,  2,  3,  7,  9, 28, 18,\n",
       "         3,  5,  5,  5, 18,  8,  7,  9, 18, 14, 11, 14, 18,  2, 11,  8,  2,  6,\n",
       "        18, 14, 11,  6,  4, 56,  5,  7, 11,  4,  2,  8,  2,  3, 14,  9,  8,  2,\n",
       "         2,  2,  9,  1, 28, 28, 14,  6,  2,  6,  2,  7, 18,  2,  6,  3, 56, 11,\n",
       "         3,  2,  8,  5,  7,  4,  6, 11, 28, 18,  4, 56, 28, 14,  2, 11,  3, 14,\n",
       "        14,  3,  3, 14, 11,  4, 18,  3, 11, 28, 11,  2, 28,  4,  7,  8, 56, 28,\n",
       "        56, 18,  1,  9,  4, 56, 14,  4, 56,  2,  6,  2,  3,  4,  7,  2,  5,  5,\n",
       "        14,  2,  6,  5, 18,  2, 14, 11, 11, 14, 28,  8, 28, 28, 11,  9,  3,  4,\n",
       "         2,  3, 14,  8,  3,  3,  7,  5, 28,  4, 18, 11, 14, 28,  5,  8, 14,  1,\n",
       "         5,  8, 56,  9,  6,  9,  3, 18, 28,  2,  5, 18, 14,  9,  5,  9,  3, 11,\n",
       "         2,  5, 14,  4, 28, 28, 28,  2,  5, 56, 14,  2,  2, 28])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen/lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 56, 100])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds[2,6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeds.mean(dim = 1).t()*(maxlen/lens.float())).t()[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(maxlen/lens.float(),embeds.mean(dim = 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a 2D tensor, but self is 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-43a58eb494e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/nlp/hw2/code/WAC.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/nlp/hw2/code/WAC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, lens)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0membeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;31m## average for non-padding embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0membeds_ave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds_ave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore2prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a 2D tensor, but self is 3D"
     ]
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5355504587155964"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dev_data.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([872])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.tensors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c88b29576794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/nlp/hw2/code/WAC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, lens)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m## build a mask for paddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0;31m## set padding to be 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0membeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "x = dev_data.tensors[0][0,:]\n",
    "y = dev_data.tensors[1][0]\n",
    "\n",
    "model.forward(x.unsqueeze(0),lens = torch.Tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4732]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(x.unsqueeze(0),lens = torch.tensor([1], dtype = torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.long, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
